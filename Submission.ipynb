{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing link prediction - Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import igraph\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testing_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_set  = list(reader)\n",
    "\n",
    "testing_set = [element[0].split(\" \") for element in testing_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "training_set = [element[0].split(\" \") for element in training_set]\n",
    "\n",
    "with open(\"node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)\n",
    "\n",
    "IDs = [element[0] for element in node_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_info = pd.read_csv('node_information.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['id','year','title','author','journal','abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_info.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>journal</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>compactification geometry and duality</td>\n",
       "      <td>Paul S. Aspinwall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>these are notes based on lectures given at tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>2000</td>\n",
       "      <td>domain walls and massive gauged supergravity p...</td>\n",
       "      <td>M. Cvetic, H. Lu, C.N. Pope</td>\n",
       "      <td>Class.Quant.Grav.</td>\n",
       "      <td>we point out that massive gauged supergravity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1003</td>\n",
       "      <td>2000</td>\n",
       "      <td>comment on metric fluctuations in brane worlds</td>\n",
       "      <td>Y.S. Myung, Gungwon Kang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recently ivanov and volovich hep-th 9912242 cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1004</td>\n",
       "      <td>2000</td>\n",
       "      <td>moving mirrors and thermodynamic paradoxes</td>\n",
       "      <td>Adam D. Helfer</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>quantum fields responding to moving mirrors ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1005</td>\n",
       "      <td>2000</td>\n",
       "      <td>bundles of chiral blocks and boundary conditio...</td>\n",
       "      <td>J. Fuchs, C. Schweigert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proceedings of lie iii clausthal july 1999 var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27765</td>\n",
       "      <td>9912289</td>\n",
       "      <td>2002</td>\n",
       "      <td>gauge fixing in the chain by chain method</td>\n",
       "      <td>A Shirzad, F Loran</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in a recent work we showed that for a hamilton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27766</td>\n",
       "      <td>9912290</td>\n",
       "      <td>2000</td>\n",
       "      <td>shuffling quantum field theory</td>\n",
       "      <td>Dirk Kreimer</td>\n",
       "      <td>Lett.Math.Phys.</td>\n",
       "      <td>we discuss shuffle identities between feynman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27767</td>\n",
       "      <td>9912291</td>\n",
       "      <td>1999</td>\n",
       "      <td>small object limit of casimir effect and the s...</td>\n",
       "      <td>O. Kenneth, S. Nussinov</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>we show a simple way of deriving the casimir p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27768</td>\n",
       "      <td>9912292</td>\n",
       "      <td>1999</td>\n",
       "      <td>1 4 pbgs and superparticle actions</td>\n",
       "      <td>F.Delduc, E. Ivanov, S. Krivonos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>karpacz poland september 21-25 1999 we constru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27769</td>\n",
       "      <td>9912293</td>\n",
       "      <td>2000</td>\n",
       "      <td>corrections to the abelian born-infeld action ...</td>\n",
       "      <td>L. Cornalba (I.H.E.S.)</td>\n",
       "      <td>JHEP</td>\n",
       "      <td>noncommutative geometry in a recent paper seib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27770 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  year                                              title  \\\n",
       "0         1001  2000              compactification geometry and duality   \n",
       "1         1002  2000  domain walls and massive gauged supergravity p...   \n",
       "2         1003  2000     comment on metric fluctuations in brane worlds   \n",
       "3         1004  2000         moving mirrors and thermodynamic paradoxes   \n",
       "4         1005  2000  bundles of chiral blocks and boundary conditio...   \n",
       "...        ...   ...                                                ...   \n",
       "27765  9912289  2002          gauge fixing in the chain by chain method   \n",
       "27766  9912290  2000                     shuffling quantum field theory   \n",
       "27767  9912291  1999  small object limit of casimir effect and the s...   \n",
       "27768  9912292  1999                 1 4 pbgs and superparticle actions   \n",
       "27769  9912293  2000  corrections to the abelian born-infeld action ...   \n",
       "\n",
       "                                 author            journal  \\\n",
       "0                     Paul S. Aspinwall                NaN   \n",
       "1           M. Cvetic, H. Lu, C.N. Pope  Class.Quant.Grav.   \n",
       "2              Y.S. Myung, Gungwon Kang                NaN   \n",
       "3                        Adam D. Helfer          Phys.Rev.   \n",
       "4               J. Fuchs, C. Schweigert                NaN   \n",
       "...                                 ...                ...   \n",
       "27765                A Shirzad, F Loran                NaN   \n",
       "27766                      Dirk Kreimer    Lett.Math.Phys.   \n",
       "27767           O. Kenneth, S. Nussinov          Phys.Rev.   \n",
       "27768  F.Delduc, E. Ivanov, S. Krivonos                NaN   \n",
       "27769            L. Cornalba (I.H.E.S.)               JHEP   \n",
       "\n",
       "                                                abstract  \n",
       "0      these are notes based on lectures given at tas...  \n",
       "1      we point out that massive gauged supergravity ...  \n",
       "2      recently ivanov and volovich hep-th 9912242 cl...  \n",
       "3      quantum fields responding to moving mirrors ha...  \n",
       "4      proceedings of lie iii clausthal july 1999 var...  \n",
       "...                                                  ...  \n",
       "27765  in a recent work we showed that for a hamilton...  \n",
       "27766  we discuss shuffle identities between feynman ...  \n",
       "27767  we show a simple way of deriving the casimir p...  \n",
       "27768  karpacz poland september 21-25 1999 we constru...  \n",
       "27769  noncommutative geometry in a recent paper seib...  \n",
       "\n",
       "[27770 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GATConv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Graph metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1001',\n",
       "  '2000',\n",
       "  'compactification geometry and duality',\n",
       "  'Paul S. Aspinwall',\n",
       "  '',\n",
       "  'these are notes based on lectures given at tasi99 we review the geometry of the moduli space of n 2 theories in four dimensions from the point of view of superstring compactification the cases of a type iia or type iib string compactified on a calabi-yau threefold and the heterotic string compactified on k3xt2 are each considered in detail we pay specific attention to the differences between n 2 theories and n 2 theories the moduli spaces of vector multiplets and the moduli spaces of hypermultiplets are reviewed in the case of hypermultiplets this review is limited by the poor state of our current understanding some peculiarities such as mixed instantons and the non-existence of a universal hypermultiplet are discussed'],\n",
       " ['1002',\n",
       "  '2000',\n",
       "  'domain walls and massive gauged supergravity potentials',\n",
       "  'M. Cvetic, H. Lu, C.N. Pope',\n",
       "  'Class.Quant.Grav.',\n",
       "  'we point out that massive gauged supergravity potentials for example those arising due to the massive breathing mode of sphere reductions in m-theory or string theory allow for supersymmetric static domain wall solutions which are a hybrid of a randall-sundrum domain wall on one side and a dilatonic domain wall with a run-away dilaton on the other side on the anti-de sitter ads side these walls have a repulsive gravity with an asymptotic region corresponding to the cauchy horizon while on the other side the runaway dilaton approaches the weak coupling regime and a non-singular attractive gravity with the asymptotic region corresponding to the boundary of spacetime we contrast these results with the situation for gauged supergravity potentials for massless scalar modes whose supersymmetric ads extrema are generically maxima and there the asymptotic regime transverse to the wall corresponds to the boundary of the ads spacetime we also comment on the possibility that the massive breathing mode may in the case of fundamental domain-wall sources stabilize such walls via a goldberger-wise mechanism'],\n",
       " ['1003',\n",
       "  '2000',\n",
       "  'comment on metric fluctuations in brane worlds',\n",
       "  'Y.S. Myung, Gungwon Kang',\n",
       "  '',\n",
       "  \"recently ivanov and volovich hep-th 9912242 claimed that the perturbation of h mu nu with nonvanishing transverse components h 5 mu is not localized on the brane because h mu nu depends on the fifth coordinate z linearly consequently it may indicate that the effective theory is unstable however we point out that such linear dependence on z can be it gauged away hence the solution does not belong to the physical one therefore even if one includes h 5 mu randall and sundrum's argument for the localized gravity on the brane remains correct\"]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_info[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = pd.read_csv('node_information.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>compactification geometry and duality</td>\n",
       "      <td>Paul S. Aspinwall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>these are notes based on lectures given at tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>2000</td>\n",
       "      <td>domain walls and massive gauged supergravity p...</td>\n",
       "      <td>M. Cvetic, H. Lu, C.N. Pope</td>\n",
       "      <td>Class.Quant.Grav.</td>\n",
       "      <td>we point out that massive gauged supergravity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1003</td>\n",
       "      <td>2000</td>\n",
       "      <td>comment on metric fluctuations in brane worlds</td>\n",
       "      <td>Y.S. Myung, Gungwon Kang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recently ivanov and volovich hep-th 9912242 cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1004</td>\n",
       "      <td>2000</td>\n",
       "      <td>moving mirrors and thermodynamic paradoxes</td>\n",
       "      <td>Adam D. Helfer</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>quantum fields responding to moving mirrors ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1005</td>\n",
       "      <td>2000</td>\n",
       "      <td>bundles of chiral blocks and boundary conditio...</td>\n",
       "      <td>J. Fuchs, C. Schweigert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proceedings of lie iii clausthal july 1999 var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27765</td>\n",
       "      <td>9912289</td>\n",
       "      <td>2002</td>\n",
       "      <td>gauge fixing in the chain by chain method</td>\n",
       "      <td>A Shirzad, F Loran</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in a recent work we showed that for a hamilton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27766</td>\n",
       "      <td>9912290</td>\n",
       "      <td>2000</td>\n",
       "      <td>shuffling quantum field theory</td>\n",
       "      <td>Dirk Kreimer</td>\n",
       "      <td>Lett.Math.Phys.</td>\n",
       "      <td>we discuss shuffle identities between feynman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27767</td>\n",
       "      <td>9912291</td>\n",
       "      <td>1999</td>\n",
       "      <td>small object limit of casimir effect and the s...</td>\n",
       "      <td>O. Kenneth, S. Nussinov</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>we show a simple way of deriving the casimir p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27768</td>\n",
       "      <td>9912292</td>\n",
       "      <td>1999</td>\n",
       "      <td>1 4 pbgs and superparticle actions</td>\n",
       "      <td>F.Delduc, E. Ivanov, S. Krivonos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>karpacz poland september 21-25 1999 we constru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27769</td>\n",
       "      <td>9912293</td>\n",
       "      <td>2000</td>\n",
       "      <td>corrections to the abelian born-infeld action ...</td>\n",
       "      <td>L. Cornalba (I.H.E.S.)</td>\n",
       "      <td>JHEP</td>\n",
       "      <td>noncommutative geometry in a recent paper seib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27770 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1                                                  2  \\\n",
       "0         1001  2000              compactification geometry and duality   \n",
       "1         1002  2000  domain walls and massive gauged supergravity p...   \n",
       "2         1003  2000     comment on metric fluctuations in brane worlds   \n",
       "3         1004  2000         moving mirrors and thermodynamic paradoxes   \n",
       "4         1005  2000  bundles of chiral blocks and boundary conditio...   \n",
       "...        ...   ...                                                ...   \n",
       "27765  9912289  2002          gauge fixing in the chain by chain method   \n",
       "27766  9912290  2000                     shuffling quantum field theory   \n",
       "27767  9912291  1999  small object limit of casimir effect and the s...   \n",
       "27768  9912292  1999                 1 4 pbgs and superparticle actions   \n",
       "27769  9912293  2000  corrections to the abelian born-infeld action ...   \n",
       "\n",
       "                                      3                  4  \\\n",
       "0                     Paul S. Aspinwall                NaN   \n",
       "1           M. Cvetic, H. Lu, C.N. Pope  Class.Quant.Grav.   \n",
       "2              Y.S. Myung, Gungwon Kang                NaN   \n",
       "3                        Adam D. Helfer          Phys.Rev.   \n",
       "4               J. Fuchs, C. Schweigert                NaN   \n",
       "...                                 ...                ...   \n",
       "27765                A Shirzad, F Loran                NaN   \n",
       "27766                      Dirk Kreimer    Lett.Math.Phys.   \n",
       "27767           O. Kenneth, S. Nussinov          Phys.Rev.   \n",
       "27768  F.Delduc, E. Ivanov, S. Krivonos                NaN   \n",
       "27769            L. Cornalba (I.H.E.S.)               JHEP   \n",
       "\n",
       "                                                       5  \n",
       "0      these are notes based on lectures given at tas...  \n",
       "1      we point out that massive gauged supergravity ...  \n",
       "2      recently ivanov and volovich hep-th 9912242 cl...  \n",
       "3      quantum fields responding to moving mirrors ha...  \n",
       "4      proceedings of lie iii clausthal july 1999 var...  \n",
       "...                                                  ...  \n",
       "27765  in a recent work we showed that for a hamilton...  \n",
       "27766  we discuss shuffle identities between feynman ...  \n",
       "27767  we show a simple way of deriving the casimir p...  \n",
       "27768  karpacz poland september 21-25 1999 we constru...  \n",
       "27769  noncommutative geometry in a recent paper seib...  \n",
       "\n",
       "[27770 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuzzywuzzy forremoving duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ab4986acb860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mMODEL_STATE_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_state.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl import batch\n",
    "from dgl.data.ppi import LegacyPPIDataset\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "from dgl.nn.pytorch.conv import GATConv\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "MODEL_STATE_FILE = path.join(path.dirname(path.abspath(__file__)), \"model_state.pth\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "def train(model, loss_fcn, device, optimizer, train_dataloader, test_dataset):\n",
    "    train_score_list = []\n",
    "    test_score_list = []\n",
    "    loss_data_list = []\n",
    "    loss_test_list = []\n",
    "    epoch_between_two_scores = 1\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                           factor=0.5, patience=5, verbose=True, \n",
    "                                                           min_lr=1e-5, eps=1e-08)\n",
    "    early_stopping = EarlyStopping(patience=30, verbose=False)\n",
    "    for epoch in range(args.epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for batch, data in enumerate(train_dataloader):\n",
    "            subgraph, features, labels = data\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(subgraph, features.float())\n",
    "            loss = loss_fcn(logits, labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        loss_data = np.array(losses).mean()\n",
    "        loss_data_list.append(loss_data)\n",
    "        \n",
    "        loss_mean = []\n",
    "        for batch, test_data in enumerate(test_dataset):\n",
    "            subgraph, features, labels = test_data\n",
    "            features = torch.tensor(features).to(device)\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "            _, loss = evaluate(features.float(), model, subgraph, labels.float(), loss_fcn)\n",
    "            loss_mean.append(loss)\n",
    "        mean_test_loss = np.array(loss_mean).mean()\n",
    "        loss_test_list.append(mean_test_loss)\n",
    "        scheduler.step(mean_test_loss)\n",
    "        early_stopping(mean_test_loss, model)\n",
    "            \n",
    "        print(\"Epoch {:05d} | Train Loss: {:.4f} | Test Loss: {:.4f}\".format(epoch + 1, loss_data, mean_test_loss))\n",
    "       \n",
    "        # validate\n",
    "        if epoch % epoch_between_two_scores == 0:\n",
    "            train_scores = []\n",
    "            for batch, data in enumerate(train_dataloader):\n",
    "                subgraph, features, labels = data\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "                train_score, _ = evaluate(features.float(), model, subgraph, labels.float(), loss_fcn)\n",
    "                train_scores.append(train_score) \n",
    "            mean_train_score = np.array(train_scores).mean()\n",
    "            train_score_list.append(mean_train_score)\n",
    "            \n",
    "            test_scores = []\n",
    "            for batch, test_data in enumerate(test_dataset):\n",
    "                subgraph, features, labels = test_data\n",
    "                features = torch.tensor(features).to(device)\n",
    "                labels = torch.tensor(labels).to(device)\n",
    "                test_score, _ = evaluate(features.float(), model, subgraph, labels.float(), loss_fcn)\n",
    "                test_scores.append(test_score)\n",
    "            mean_test_score = np.array(test_scores).mean()\n",
    "            test_score_list.append(mean_test_score)\n",
    "            print(\"   F1-Score | Train       {:.2%} | Test       {:.2%} \".format(mean_train_score, mean_test_score))\n",
    "        \n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    history = {\n",
    "        'score':{\n",
    "            'train': train_score_list,\n",
    "            'test': test_score_list,\n",
    "            'epoch_between_two_scores': epoch_between_two_scores,\n",
    "        },\n",
    "        'loss':{\n",
    "            'train': loss_data_list,\n",
    "        }\n",
    "    }\n",
    "    return history\n",
    "\n",
    "\n",
    "def test(model, loss_fcn, device, test_dataloader):\n",
    "    test_scores = []\n",
    "    for batch, test_data in enumerate(test_dataloader):\n",
    "        subgraph, features, labels = test_data\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        test_scores.append(evaluate(features, model, subgraph, labels.float(), loss_fcn)[0])\n",
    "    mean_scores = np.array(test_scores).mean()\n",
    "    print(\"F1-Score: {:.4f}\".format(np.array(test_scores).mean()))\n",
    "    return mean_scores\n",
    "\n",
    "\n",
    "def evaluate(features, model, subgraph, labels, loss_fcn):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.graph = subgraph\n",
    "        output = model(subgraph, features.float())\n",
    "        loss_data = loss_fcn(output, labels.float())\n",
    "        predict = np.where(output.data.cpu().numpy() >= 0.5, 1, 0)\n",
    "        score = f1_score(labels.data.cpu().numpy(), predict, average=\"micro\")\n",
    "        return score, loss_data.item()\n",
    "\n",
    "\n",
    "def collate_fn(sample):\n",
    "    graphs, features, labels = map(list, zip(*sample))\n",
    "    graph = batch(graphs)\n",
    "    features = torch.from_numpy(np.concatenate(features))\n",
    "    labels = torch.from_numpy(np.concatenate(labels))\n",
    "    return graph, features, labels\n",
    "\n",
    "def plot_score_fc(history):\n",
    "    step = history['score']['epoch_between_two_scores']\n",
    "    epoch_list = range(0, len(history['score']['train']) * step, step)\n",
    "    \n",
    "    fig = plt.figure(figsize = (13, 6))\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    train_score = history['score']['train']\n",
    "    ax1.plot(epoch_list, train_score)\n",
    "\n",
    "    test_score = history['score']['test']\n",
    "    ax1.plot(epoch_list, test_score)\n",
    "    \n",
    "    ax1.legend(['train score',' test score'])\n",
    "    ax1.set_xlabel('Epochs', size = 15)\n",
    "    ax1.set_ylabel('F1-score', size = 15)\n",
    "    ax1.set_title('Score of the train and test set each {step} epochs'.format(step = step), size = 20)\n",
    "\n",
    "    ax1.set_xlim(0, epoch_list[-1])\n",
    "    ax1.set_ylim(0,1)\n",
    "\n",
    "    ax1.set_yticks([value/10 for value in range(1, 11)])\n",
    "    fig.savefig('score.png')\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers, input_size, hidden_size, output_size, nonlinearity):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_feats=input_size,\n",
    "                                    out_feats=256,\n",
    "                                    num_heads=4,\n",
    "                                   activation = F.elu\n",
    "                                  )\n",
    "        self.gat2 = GATConv(in_feats=256 * 4,\n",
    "                                    out_feats=256,\n",
    "                                    num_heads=4,\n",
    "                                   activation = F.elu\n",
    "                                  )\n",
    "        self.gat4 = GATConv(in_feats=256 * 4,\n",
    "                                    out_feats=256,\n",
    "                                    num_heads=4,\n",
    "                                   activation = F.elu\n",
    "                                  )\n",
    "        self.gat3 = GATConv(in_feats=256 * 4,\n",
    "                                    out_feats=121,\n",
    "                                    num_heads=6,\n",
    "                                   activation= F.elu\n",
    "                                  )\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.flatten2 = nn.Flatten()\n",
    "        self.linear0 = nn.Linear(input_size, 256 * 4)\n",
    "        self.linear1 = nn.Linear(256 * 4, 256 * 4)\n",
    "        self.linear2 = nn.Linear(121 * 3, 121)\n",
    "        self.linear3 = nn.Linear(256 * 4, 121)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, subgraph,  inputs):\n",
    "        hidden = self.gat1(subgraph, inputs)\n",
    "        hidden = self.flatten1(hidden)\n",
    "        hidden2 = hidden\n",
    "        hidden = (hidden + F.relu(self.dropout(self.linear0(inputs)))) / 2\n",
    "        \n",
    "        shortcut = hidden\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = self.gat2(subgraph, hidden)\n",
    "        hidden = self.flatten2(hidden)\n",
    "        \n",
    "        hidden2 = self.dropout(hidden2)\n",
    "        hidden2 = self.gat4(subgraph, hidden2)\n",
    "        hidden2 = self.flatten2(hidden2)\n",
    "        \n",
    "        hidden = (hidden +hidden2+ F.relu(self.dropout(self.linear1(shortcut)))) / 3\n",
    "        shortcut = hidden \n",
    "        \n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = self.gat3(subgraph,hidden)\n",
    "        hidden_mean = (hidden.mean(dim = 1) + F.relu(self.linear3(shortcut))) / 2\n",
    "        hidden_max = (hidden.max(dim = 1).values + F.relu(self.linear3(shortcut))) / 2\n",
    "        hidden_min = (hidden.min(dim = 1).values + F.relu(self.linear3(shortcut))) / 2\n",
    "        hidden = torch.cat([hidden_mean, hidden_max, hidden_min], dim = 1)\n",
    "        hidden = torch.sigmoid(self.linear2(hidden))\n",
    "        return hidden\n",
    "\n",
    "def main(args):\n",
    "    # create the dataset\n",
    "    train_dataset, test_dataset = LegacyPPIDataset(mode=\"train\"), LegacyPPIDataset(mode=\"test\")\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, collate_fn=collate_fn)\n",
    "    n_features, n_classes = train_dataset.features.shape[1], train_dataset.labels.shape[1]\n",
    "\n",
    "    # create the model, loss function and optimizer\n",
    "    device = torch.device(\"cpu\" if args.gpu < 0 else \"cuda:\" + str(args.gpu))\n",
    "    model = Model(n_layers=None, input_size=n_features,hidden_size=256, output_size=n_classes, nonlinearity=F.elu).to(device)\n",
    "    loss_fcn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "\n",
    "    # train and test\n",
    "    if args.mode == \"train\":\n",
    "        history = train(model, loss_fcn, device, optimizer, train_dataloader, test_dataset)\n",
    "        torch.save(model.state_dict(), MODEL_STATE_FILE)\n",
    "        if args.verbose:\n",
    "            plot_score_fc(history)\n",
    "        return history, test(model, loss_fcn, device, test_dataloader)\n",
    "    model.load_state_dict(torch.load(MODEL_STATE_FILE, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    return test(model, loss_fcn, device, test_dataloader)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\",  choices=[\"train\", \"test\"], default=\"test\")\n",
    "    parser.add_argument(\"--gpu\", type=int, default=-1, help=\"GPU to use. Set -1 to use CPU.\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=400)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=2)\n",
    "    parser.add_argument(\"--verbose\", type=bool, default= False)\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
